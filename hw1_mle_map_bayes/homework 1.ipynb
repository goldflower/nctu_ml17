{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from numpy.linalg import *\n",
    "from numpy import dot\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('X_train.csv', header=None, names=['X','Y'])\n",
    "t = pd.read_csv('T_train.csv', header=None, names=['H'])\n",
    "train['target'] = t['H']\n",
    "train = train.sample(frac=1)\n",
    "test_set = pd.read_csv('X_test.csv', header=None, names=['X','Y'])\n",
    "#validation, train = np.split(csv.sample(frac=1), [len(csv)//5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# validation = validation[:200]\n",
    "# train = train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Gaussian2D():\n",
    "    \n",
    "    def __init__(self, mean_x, mean_y, variance_x=1, variance_y=1):\n",
    "        self.mean_x = mean_x\n",
    "        self.mean_y = mean_y\n",
    "        self.variance_x = variance_x\n",
    "        self.variance_y = variance_y\n",
    "        self.prob = None\n",
    "        \n",
    "    def probability(self, x, y):\n",
    "        self.prob = (np.exp(-((x-self.mean_x)**2)/(2*self.variance_x**2) - \n",
    "                             ((y-self.mean_y)**2)/(2*self.variance_y**2)))\n",
    "        return self.prob\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Gaussian2D with mean {}, {}; variance {}, {}'.format(self.mean_x, self.mean_y, self.variance_x, self.variance_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class utility():\n",
    "    \n",
    "    def data_to_graph(self, data):\n",
    "        graph = np.zeros((1081, 1081))\n",
    "        M = data['target'].max()\n",
    "        for index, row in data.iterrows():\n",
    "            graph[row['X']-1, row['Y']-1] = row['target']\n",
    "        return graph\n",
    "    \n",
    "    def find_peaks(self, graph, window_size_x=20, window_size_y=20, put=1):\n",
    "        # put: 一個window放幾個basis\n",
    "        peaks = []\n",
    "        for i in range(0, graph.shape[1]-graph.shape[1]%window_size_x, window_size_x):\n",
    "            fat_column = graph[:, i:i+window_size_x]\n",
    "            for j in range(0, graph.shape[0]-graph.shape[0]%window_size_y, window_size_y):\n",
    "                # 每個window放兩個, 如果最大值是0, 就只放一個隨機點  --- 改成放在中間\n",
    "                # 在training時使用後面的flag, e.g. random / peak\n",
    "                window = fat_column[j:j+window_size_y, :].flatten()\n",
    "                #print(np.max(window))\n",
    "                if np.max(window) == 0:\n",
    "                    peaks.append((j+window_size_y//2, i + window_size_x//2, 'random'))\n",
    "                    #peaks.append((np.random.randint(j, j+window_size_y), np.random.randint(i, i+window_size_x), 'random'))\n",
    "                    #continue\n",
    "                elif np.max(window) is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    peak = np.where(window == max(window))[0]\n",
    "                    peaks.append((j+int(peak[0])//window_size_x, i+int(peak[0])%window_size_x, 'peak'))\n",
    "                # 一個window可能有兩個以上的peak, 只取兩個, 未滿兩個以random補  ---- 不這樣做了, 每格只放一個\n",
    "#                 peak = np.where(window == max(window))[0]\n",
    "#                 #peaks.append((j+int(peak[0])//window_size_x, i+int(peak[0])%window_size_x, 'peak'))\n",
    "#                 if len(peak) > 1:\n",
    "#                     peaks.append((j+int(peak[0])//window_size_x, i+int(peak[0])%window_size_x, 'peak'))\n",
    "#                     #peaks.append((j+int(peak[1])//window_size_x, i+int(peak[1])%window_size_x, 'peak'))\n",
    "#                 # window裡面最高的是0, 隨便放一個就好\n",
    "#                 else:\n",
    "#                     peak = (j+int(peak[0])//window_size_x, i+int(peak[0])%window_size_x, 'peak')\n",
    "#                     peaks.append(peak)\n",
    "# #                     while True:\n",
    "# #                         r = (np.random.randint(j, j+window_size_y), np.random.randint(i, i+window_size_x), 'random')\n",
    "# #                         if r[0] == peak[0] and r[1] == peak[1]:\n",
    "# #                             continue\n",
    "# #                         else:\n",
    "# #                             peaks.append(r)\n",
    "# #                             break\n",
    "        return peaks\n",
    "    \n",
    "    # implement of k_fold spliter, 封裝方式感覺不好, 有機會改一下\n",
    "    def k_fold_spliter(self, data, k=5, return_indicies=False):\n",
    "        #data = data.sample(frac=1)\n",
    "        train_val_pair = [] # data sets of each fold\n",
    "        indicies = [] # index of (train, val)\n",
    "        for i in range(0, len(data), len(data)//k):\n",
    "            if i + len(data)//k >= len(data):\n",
    "                val = data.iloc[i:]\n",
    "                val_index = list(range(i, len(data)))\n",
    "                train = data.iloc[:i]\n",
    "                train_index = list(range(i))\n",
    "                indicies.append((train_index, val_index))\n",
    "                train_val_pair.append((train, val))\n",
    "            else:\n",
    "                val = data.iloc[i:i+len(data)//k]\n",
    "                val_index = list(range(i, i+len(data)//k))\n",
    "                train = data.iloc[:i].append(data.iloc[i+len(data)//k:])\n",
    "                train_index = list(range(i))\n",
    "                train_index.extend(list(range(i+len(data)//k, len(data))))\n",
    "                indicies.append((train_index, val_index))\n",
    "                train_val_pair.append((train, val))\n",
    "        if return_indicies:     \n",
    "            return(train_val_pair, indicies)\n",
    "        else:\n",
    "            return train_val_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class bayesian_linear_regression(utility):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_basis = None\n",
    "        self.design_matrix = None\n",
    "        self.W_ML = None\n",
    "        self.W_MAP = None\n",
    "        self.m_N = None\n",
    "        self.S_N_inv = None\n",
    "        self.predictive_distribution_function = None\n",
    "\n",
    "    def create_predictive_distribution_function(self, input_data, target, alpha, beta):\n",
    "        print('compute S_N_inv')\n",
    "        S_N_inv = alpha * np.eye(len(self.feature_basis)) + beta * dot(self.design_matrix.T, self.design_matrix)\n",
    "        # 為了方便, 將m0設為zero\n",
    "        print('compute m_N')\n",
    "        m_N = beta * solve(S_N_inv, dot(self.design_matrix.T, target))\n",
    "        self.S_N_inv = S_N_inv\n",
    "        self.m_N = m_N\n",
    "        def func(x, S_N_inv, m_N, design_matrix, beta=beta):\n",
    "            mu = dot(m_N.T, design_matrix)\n",
    "            #s_N_square = 1.0/beta + dot(design_matrix.T, solve(S_N_inv, design_matrix))\n",
    "            #return (mu, s_N_square)\n",
    "            return mu\n",
    "        self.predictive_distribution_function = func\n",
    "        \n",
    "    # 1. create feature basis\n",
    "    def create_grid_gaussian_basis(self, var_x=100, var_y=100, grid_size_land=70, grid_size_sea=100, heuristic=True, show=False):\n",
    "        # multiple regression\n",
    "        # 座標點值1~1081, 切grid\n",
    "        # 假設都由高斯分布組成\n",
    "        # mean為坐標點, var隨意設\n",
    "        feature_basis = [1] # 1: bias\n",
    "        for i in range(200, 1082, grid_size_land):\n",
    "            for j in range(1, 1082, grid_size_land):\n",
    "                feature_basis.append(Gaussian2D(i, j, var_x, var_y))\n",
    "        for i in range(1, 201, grid_size_sea):\n",
    "            for j in range(1, 1082, grid_size_sea):\n",
    "                if heuristic:\n",
    "                    feature_basis.append(Gaussian2D(i, j, 2*var_x, 2*var_y))\n",
    "                else:\n",
    "                    feature_basis.append(Gaussian2D(i, j, var_x, var_y))\n",
    "        self.feature_basis = feature_basis\n",
    "        if show:\n",
    "            return self.feature_basis        \n",
    "\n",
    "    def test_overfit_basis(self, train, var_x=100, var_y=100, show=False):# 每個座標放高斯\n",
    "        feature_basis = [1]\n",
    "        for index, row in train.iterrows():\n",
    "            feature_basis.append(Gaussian2D(row['X'], row['Y'], var_x, var_y))\n",
    "        self.feature_basis = feature_basis\n",
    "        if show:\n",
    "            return feature_basis\n",
    "    \n",
    "    def create_peak_gaussian_basis(self, train, p_var_x=5, p_var_y=5, r_var_x=20, r_var_y=20, window_size_x=None, window_size_y=None, show=False):\n",
    "        # 設計方式如pdf\n",
    "        graph = self.data_to_graph(train)\n",
    "        if window_size_x is None:\n",
    "            window_size_x = 20\n",
    "        if window_size_y is None:\n",
    "            window_size_y = 20\n",
    "        peaks = self.find_peaks(graph, window_size_x, window_size_y)\n",
    "        feature_basis = [1] # 1: bias\n",
    "        for peak in peaks:\n",
    "            if peak[2] == 'peak':\n",
    "                # 此處不consistence, create basis時使用x,y; 但寫peak時寫成row,col... 有空改\n",
    "                feature_basis.append(Gaussian2D(peak[1], peak[0], p_var_x, p_var_y))\n",
    "            else:\n",
    "                feature_basis.append(Gaussian2D(peak[1], peak[0], r_var_x, r_var_y))\n",
    "        self.feature_basis = feature_basis\n",
    "        if show:\n",
    "            return self.feature_basis\n",
    "    \n",
    "    # 2. create design matrix\n",
    "    def create_design_matrix(self, data, change=True, return_result=False, show=False, n_workers=None, verbose=True):\n",
    "        print('create design matrix...')\n",
    "        design_matrix = np.zeros((len(data), len(self.feature_basis)))\n",
    "        design_matrix[:,0] = 1\n",
    "        num_features = design_matrix.shape[1]\n",
    "        if n_workers is None:\n",
    "            for i in range(1, num_features): # by column, 0th is basis, skip\n",
    "                design_matrix[:,i] = data.apply(lambda row: self.feature_basis[i].probability(row['X'], row['Y']), axis=1)\n",
    "                if verbose:\n",
    "#                     done = 80 * i // num_features\n",
    "#                     sys.stdout.write(\"\\r[%s%s]\" % ('▶' * done, '•' * (80-done)))\n",
    "                    done = 100 * i // num_features\n",
    "                    sys.stdout.write('\\r complete {}%'.format(done))\n",
    "            print()\n",
    "        else:\n",
    "            pass\n",
    "            result_queue = multiprocessing.Queue()\n",
    "            design_matricies = []\n",
    "            # 以feature數去平行處理\n",
    "            for i in range(1, num_features, num_features//n_workers):\n",
    "                if i + num_features//n_workers >= num_features:\n",
    "                    design_matricies.append()\n",
    "        if change:\n",
    "            self.design_matrix = design_matrix\n",
    "        if show:\n",
    "            print(self.design_matrix)\n",
    "        if return_result:\n",
    "            return design_matrix\n",
    "    \n",
    "    # 3_1. create W_ML\n",
    "    def fit_with_W_ML(self, input_data, target, k_fold=None, show=False, get_WLs=False):\n",
    "        self.create_design_matrix(input_data)\n",
    "        print('compute W_ML...')\n",
    "        self.W_ML = dot(pinv(self.design_matrix), target)\n",
    "        \n",
    "#         if k_fold is None:\n",
    "#             self.create_design_matrix(input_data)\n",
    "#             print('compute W_ML...')\n",
    "#             self.W_ML = dot(pinv(self.design_matrix), target)\n",
    "            \n",
    "#         else:\n",
    "#             W_MLs = []\n",
    "#             data = input_data.copy()\n",
    "#             data['target'] = target.values\n",
    "#             count = 0\n",
    "#             design_matrix = self.create_design_matrix(input_data, False, True)\n",
    "#             k_fold_pairs = self.k_fold_spliter(input_data, 5, return_indicies=True)\n",
    "#             for i in range(k_fold):\n",
    "#                 train = k_fold_pairs[0][i][0]\n",
    "#                 val = k_fold_pairs[0][i][1]\n",
    "#                 train_index = k_fold_pairs[1][i][0]\n",
    "#                 #print(train_index)\n",
    "#                 val_index = k_fold_pairs[1][i][1]\n",
    "#                 #print(val_index)\n",
    "#                 count += 1\n",
    "#                 print('compute W_ML {}/{} ...'.format(count, k_fold))\n",
    "#                 W_ML = dot(pinv(design_matrix[train_index,:]), target.iloc[train_index])\n",
    "#                 W_MLs.append(W_ML)\n",
    "#                 print('train fold', i, self.evaluate_W_ML(train, target.iloc[train_index], W_ML))\n",
    "#                 print('val fold', i, self.evaluate_W_ML(val, target.iloc[val_index], W_ML))\n",
    "#             W = np.zeros(W_MLs[0].shape)\n",
    "#             for W_ML in W_MLs:\n",
    "#                 W += W_ML\n",
    "#             self.W_ML = W / k_fold\n",
    "        \n",
    "        if show:\n",
    "            return self.W_ML\n",
    "        \n",
    "    # 3_2. create W_MAP\n",
    "    def fit_with_W_MAP(self, input_data=None, target=None, k_fold=None, show=False, s=20, beta=1000000, reg=0.1):\n",
    "        if self.design_matrix is None:\n",
    "            self.create_design_matrix(input_data)\n",
    "        if k_fold is None:\n",
    "            self.W_MAP = reg*np.eye(len(self.feature_basis)) + dot(self.design_matrix.T, self.design_matrix)\n",
    "            self.W_MAP = dot(inv(self.W_MAP), dot(self.design_matrix.T, target))\n",
    "#             t_tilta = target\n",
    "#             t_tilta *= np.sqrt(beta)\n",
    "#             t_tilta = np.append(t_tilta, [0]*len(self.feature_basis))\n",
    "\n",
    "#             design_matrix_tilta = self.design_matrix[train_index, :]\n",
    "#             design_matrix_tilta *= np.sqrt(beta)\n",
    "#             design_matrix_tilta = np.append(design_matrix_tilta, s*np.eye(len(self.feature_basis)), axis=0)\n",
    "\n",
    "#             q, r = np.linalg.qr(design_matrix_tilta)\n",
    "#             W_MAP = dot(dot(inv(r), q.T), t_tilta)\n",
    "#             self.W_MAP = W_MAP\n",
    "#         q, r = np.linalg.qr(self.design_matrix)\n",
    "#         self.W_MAP = dot(dot(inv(r), q.T), target)\n",
    "        else:\n",
    "            if type(beta) != list:\n",
    "                betas = range(1000000, 20000001, 1000000)\n",
    "            else:\n",
    "                betas = beta\n",
    "            data = input_data.copy()\n",
    "            data['target'] = target.values\n",
    "            k_fold_pairs = self.k_fold_spliter(input_data, k_fold, return_indicies=True)\n",
    "            best_beta = None\n",
    "            print(betas)\n",
    "            for beta in betas:\n",
    "                W_MAPs = []\n",
    "                count = 0\n",
    "                print('beta {}'.format(beta))\n",
    "                train_err = 0\n",
    "                val_err = 0\n",
    "                #reg = reg / 5\n",
    "                for i in range(k_fold):\n",
    "                    train = k_fold_pairs[0][i][0]\n",
    "                    val = k_fold_pairs[0][i][1]\n",
    "                    train_index = k_fold_pairs[1][i][0]\n",
    "                    #print(train_index)\n",
    "                    val_index = k_fold_pairs[1][i][1]\n",
    "                    #print(val_index)\n",
    "                    count += 1\n",
    "                    print('compute W_MAP {}/{} ...'.format(count, k_fold))\n",
    "                    t_tilta = target.iloc[train_index]\n",
    "                    t_tilta *= np.sqrt(beta)\n",
    "                    t_tilta = np.append(t_tilta, [0]*len(self.feature_basis))\n",
    "                    \n",
    "                    design_matrix_tilta = self.design_matrix[train_index, :]\n",
    "                    design_matrix_tilta *= np.sqrt(beta)\n",
    "                    design_matrix_tilta = np.append(design_matrix_tilta, s*np.eye(len(self.feature_basis)), axis=0)\n",
    "\n",
    "                    \n",
    "                    q, r = np.linalg.qr(design_matrix_tilta)\n",
    "                    W_MAP = dot(dot(inv(r), q.T), t_tilta)\n",
    "                    #W_MAP = reg*np.eye(len(self.feature_basis)) + dot(self.design_matrix.T, self.design_matrix)\n",
    "                    #W_MAP = dot(inv(W_MAP), dot(self.design_matrix.T, target))\n",
    "                    tre = self.evaluate_W_MAP(train, target.iloc[train_index], W_MAP)\n",
    "                    print('train fold', i, tre)\n",
    "                    train_err += tre\n",
    "                    vae = self.evaluate_W_MAP(val, target.iloc[val_index], W_MAP)\n",
    "                    print('val fold', i, vae)\n",
    "                    val_err += vae\n",
    "                train_err /= k_fold\n",
    "                val_err /= k_fold\n",
    "                print('overall err of beta {}: {}'.format(beta, val_err))\n",
    "                if best_beta is None:\n",
    "                    best_beta = (val_err, beta, W_MAP)\n",
    "                elif val_err < best_beta[0]:\n",
    "                    best_beta = (val_err, beta, W_MAP)\n",
    "            print('best beta is', best_beta[1])\n",
    "            self.W_MAP = best_beta[2]\n",
    "            self.beta = best_beta[1]\n",
    "                \n",
    "        if show:\n",
    "            return self.W_MAP\n",
    "    \n",
    "    # 3_3. create predictive distribution model\n",
    "    def fit_with_predictive_distribution_function(self, input_data, target, alpha=50, beta=10):\n",
    "        if self.design_matrix is None:\n",
    "            self.create_design_matrix(input_data)\n",
    "        print('creating predictive distribution model')\n",
    "        self.create_predictive_distribution_function(input_data, target, alpha, beta)\n",
    "        \n",
    "    # 4. predict new data\n",
    "    def predict_with_W_ML(self, x, y, W_ML=None):\n",
    "        if W_ML is None:\n",
    "            W_ML = self.W_ML\n",
    "        predict = W_ML[0] * self.feature_basis[0]\n",
    "        for i in range(1, len(W_ML)):\n",
    "            predict += W_ML[i] * self.feature_basis[i].probability(x, y)\n",
    "        return predict\n",
    "    \n",
    "    def predict_with_W_MAP(self, x, y, W_MAP=None):\n",
    "        if W_MAP is None:\n",
    "            W_MAP = self.W_MAP\n",
    "        predict = W_MAP[0] * self.feature_basis[0]\n",
    "        for i in range(1, len(W_MAP)):\n",
    "            predict += W_MAP[i] * self.feature_basis[i].probability(x, y)\n",
    "        return predict\n",
    "\n",
    "    def predict_with_predictive_distribution_function(self, x, y):\n",
    "        phi_X = [1]\n",
    "        phi_X.extend([feature.probability(x, y) for feature in self.feature_basis[1:]])\n",
    "        phi_X = np.array(phi_X).reshape(len(self.feature_basis),1)\n",
    "        predict = dot(self.m_N.T, phi_X)\n",
    "        return predict[0]\n",
    "    \n",
    "\n",
    "    # 5. evaluate model\n",
    "    def evaluate_W_ML(self, test_data_input, target, W_ML=None):\n",
    "        print('evaluating with W_ML...')\n",
    "        if W_ML is None:\n",
    "            W_ML = self.W_ML\n",
    "        x = np.array(test_data_input)\n",
    "        t = np.array(target)\n",
    "        err = 0\n",
    "        for i in range(len(x)):\n",
    "            predict = self.predict_with_W_ML(x[i,0], x[i,1], W_ML=W_ML)\n",
    "            err += (predict - t[i])**2\n",
    "        err /= len(x)\n",
    "        return err\n",
    "    \n",
    "    def evaluate_W_MAP(self, test_data_input, target, W_MAP=None):\n",
    "        print('evaluating with W_MAP...')\n",
    "        if W_MAP is None:\n",
    "            W_MAP = self.W_MAP\n",
    "        x = np.array(test_data_input)\n",
    "        t = np.array(target)\n",
    "        err = 0\n",
    "        for i in range(len(x)):\n",
    "            predict = self.predict_with_W_MAP(x[i,0], x[i,1], W_MAP=W_MAP)\n",
    "            err += (predict - t[i])**2\n",
    "        err /= len(x)\n",
    "        return err\n",
    "    \n",
    "    def evaluate_predictive_distribution_function(self, test_data_input, target):\n",
    "        print('evaluating with predictive distribution function...')\n",
    "        x = np.array(test_data_input)\n",
    "        t = np.array(target)\n",
    "        err = 0\n",
    "        for i in range(len(x)):\n",
    "            predict = self.predict_with_predictive_distribution_function(x[i,0], x[i,1])\n",
    "            err += (predict - t[i])**2\n",
    "        err /= len(x)\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 用於比較各種參數\n",
    "def compare_train_validation(csv, i=1, j=81, k=2, compare='variance', get_models=False, v=None):\n",
    "    models = []\n",
    "    val, train = np.split(csv.sample(frac=1), [len(csv)//5])\n",
    "    train_errs = []\n",
    "    val_errs = []\n",
    "    # 比較variance\n",
    "    if compare == 'variance':\n",
    "        for v in range(i, j, k):\n",
    "            np.random.seed(1)\n",
    "            clf = bayesian_linear_regression()\n",
    "            # just a heuristic, 海平面應該比較平緩, 陸地的variance較低\n",
    "            # grid default 20x20\n",
    "            clf.create_peak_gaussian_basis(train, v, v, 70, 70)\n",
    "            clf.fit_with_W_ML(train[['X','Y']], train['target'])\n",
    "            models.append(clf)\n",
    "            train_err = clf.evaluate_W_ML(train[['X', 'Y']], train['target'])\n",
    "            train_errs.append(train_err)\n",
    "            val_err = clf.evaluate_W_ML(val[['X','Y']], val['target'])\n",
    "            val_errs.append(val_err)\n",
    "            print('train err of {}: {}'.format(v, train_err))\n",
    "            print('val err of {}: {}'.format(v, val_err))\n",
    "        a, = plt.plot(range(i, j, k), np.log(train_errs), 'ro', label=\"train error\")\n",
    "        b, = plt.plot(range(i, j, k), np.log(val_errs), 'b^', label=\"validation error\")\n",
    "        plt.legend(handles=[a, b])\n",
    "        plt.title('compare variance with grid size 20')\n",
    "        plt.xlabel('variance')\n",
    "        plt.ylabel('log_error')\n",
    "        plt.savefig('train_val_variance_err_differ.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    # 比較grid size\n",
    "    elif compare == 'gridsize':\n",
    "        if v is None:\n",
    "            v = 50\n",
    "        for grid_size in range(i, j, k):\n",
    "            np.random.seed(1)\n",
    "            clf = bayesian_linear_regression()\n",
    "            clf.create_peak_gaussian_basis(train, v, v, 70, 70, grid_size, grid_size)\n",
    "            clf.fit_with_W_ML(train[['X','Y']], train['target'])\n",
    "            models.append(clf)\n",
    "            train_err = clf.evaluate_W_ML(train[['X', 'Y']], train['target'])\n",
    "            train_errs.append(train_err)\n",
    "            val_err = clf.evaluate_W_ML(val[['X','Y']], val['target'])\n",
    "            val_errs.append(val_err)\n",
    "            print('train err of {}: {}'.format(grid_size, train_err))\n",
    "            print('val err of {}: {}'.format(grid_size, val_err))\n",
    "        plt.style.use('ggplot')\n",
    "        a, = plt.plot(range(i, j, k), np.log(train_errs), 'ro', label=\"train error\")\n",
    "        b, = plt.plot(range(i, j, k), np.log(val_errs), 'b^', label=\"validation error\")\n",
    "        plt.legend(handles=[a, b])\n",
    "        plt.title('compare grid size with variance {}'.format(v))\n",
    "        plt.xlabel('grid_size')\n",
    "        plt.ylabel('log_error')\n",
    "        plt.savefig('train_val_grid_err_differ.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    # 比較lambda\n",
    "    elif compare == 'reg':\n",
    "        if v is None:\n",
    "            v = 20\n",
    "        grid_size = 25\n",
    "        for reg in range(i, j, k):\n",
    "            np.random.seed(1)\n",
    "            clf = bayesian_linear_regression()\n",
    "            clf.create_peak_gaussian_basis(train, v, v, 70, 70, grid_size, grid_size)\n",
    "            clf.fit_with_W_MAP(train[['X','Y']], train['target'], reg=reg/5)\n",
    "            models.append(clf)\n",
    "            train_err = clf.evaluate_W_MAP(train[['X', 'Y']], train['target'])\n",
    "            train_errs.append(train_err)\n",
    "            val_err = clf.evaluate_W_MAP(val[['X','Y']], val['target'])\n",
    "            val_errs.append(val_err)\n",
    "            print('train err of {}: {}'.format(grid_size, train_err))\n",
    "            print('val err of {}: {}'.format(grid_size, val_err))\n",
    "        plt.style.use('ggplot')\n",
    "        a, = plt.plot(range(i, j, k), np.log(train_errs), 'ro', label=\"train error\")\n",
    "        b, = plt.plot(range(i, j, k), np.log(val_errs), 'b^', label=\"validation error\")\n",
    "        plt.legend(handles=[a, b])\n",
    "        plt.title('compare reg differ with variance {}'.format(v))\n",
    "        plt.xlabel('reg')\n",
    "        plt.ylabel('log_error')\n",
    "        plt.savefig('train_val_reg_err_differ.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    if get_models:\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create design matrix...\n",
      " complete 99%\n",
      "compute W_ML...\n",
      "evaluating with W_ML...\n",
      "evaluating with W_ML...\n",
      "train err of 10: 1.7108035189237509e-22\n",
      "val err of 10: 377323.05850975006\n",
      "create design matrix...\n",
      " complete 37%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2756\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2739\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 2740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5696bb12f1e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_train_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#比variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5c1d931d98e8>\u001b[0m in \u001b[0;36mcompare_train_validation\u001b[0;34m(csv, i, j, k, compare, get_models, v)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# grid default 20x20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_peak_gaussian_basis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_with_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mfit_with_W_ML\u001b[0;34m(self, input_data, target, k_fold, show, get_WLs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# 3_1. create W_ML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_WLs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_design_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compute W_ML...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesign_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mcreate_design_matrix\u001b[0;34m(self, data, change, return_result, show, n_workers, verbose)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# by column, 0th is basis, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mdesign_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_basis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#                     done = 80 * i // num_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4201\u001b[0m                 \u001b[0mempty_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m                 dummy = Series(empty_arr, index=self._get_axis(axis),\n\u001b[0;32m-> 4203\u001b[0;31m                                dtype=values.dtype)\n\u001b[0m\u001b[1;32m   4204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4205\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2756\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_train_validation(train[:500], 10, 80, 10) #比variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create design matrix...\n",
      " complete 99%\n",
      "compute W_ML...\n",
      "evaluating with W_ML...\n",
      "evaluating with W_ML...\n",
      "train err of 80: 804.0849048182375\n",
      "val err of 80: 3167.3169644701948\n",
      "create design matrix...\n",
      " complete 81%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1ae92b56bd52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_train_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gridsize'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#比gridsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5c1d931d98e8>\u001b[0m in \u001b[0;36mcompare_train_validation\u001b[0;34m(csv, i, j, k, compare, get_models, v)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesian_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_peak_gaussian_basis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_with_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mfit_with_W_ML\u001b[0;34m(self, input_data, target, k_fold, show, get_WLs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# 3_1. create W_ML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_with_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_WLs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_design_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compute W_ML...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesign_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mcreate_design_matrix\u001b[0;34m(self, data, change, return_result, show, n_workers, verbose)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# by column, 0th is basis, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mdesign_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_basis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#                     done = 80 * i // num_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4206\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4207\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[0;32m-> 4208\u001b[0;31m                                         labels=labels)\n\u001b[0m\u001b[1;32m   4209\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4210\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.reduce (pandas/lib.c:45030)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.Reducer.get_result (pandas/lib.c:34673)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# by column, 0th is basis, skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mdesign_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_basis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#                     done = 80 * i // num_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;31m# if we have something that is Index-like, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m         \u001b[0;31m# use this, e.g. DatetimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2154\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_values'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;34m\"\"\" return the internal repr of this data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36minternal_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4075\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4077\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4078\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4079\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_train_validation(train[:500], 80, 10, -10, compare='gridsize') #比gridsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#compare_train_validation(train, 10, 80, 10, compare='reg') #比lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create design matrix...\n",
      " complete 99%\n",
      "compute W_ML...\n",
      "evaluating with W_ML...\n",
      "evaluating with W_ML...\n",
      "1.45874953671e-16 105040689223.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-71f875a6b116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mval_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_with_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ML_target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ML_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-71f875a6b116>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mval_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_with_W_ML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ML_target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mML\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ML_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mpredict_with_W_ML\u001b[0;34m(self, x, y, W_ML)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_ML\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_basis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_ML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mpredict\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mW_ML\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_basis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-640014073dc6>\u001b[0m in \u001b[0;36mprobability\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         self.prob = (np.exp(-((x-self.mean_x)**2)/(2*self.variance_x**2) - \n\u001b[0;32m---> 12\u001b[0;31m                              ((y-self.mean_y)**2)/(2*self.variance_y**2)))\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ml\n",
    "v = 20\n",
    "t = train[:1000]\n",
    "val, tr = np.split(t, [len(t)//5])\n",
    "clf3 = bayesian_linear_regression()\n",
    "clf3.create_peak_gaussian_basis(tr, v, v, 70, 70, 25, 25)\n",
    "clf3.fit_with_W_ML(tr[['X','Y']], tr['target'])\n",
    "train_err = clf3.evaluate_W_ML(tr[['X','Y']], tr['target'])\n",
    "val_err = clf3.evaluate_W_ML(val[['X', 'Y']], val['target'])\n",
    "print(train_err, val_err)\n",
    "lst = np.array([clf3.predict_with_W_ML(row['X'], row['Y']) for index, row in test_set.iterrows()])\n",
    "test_set['ML_target'] = lst\n",
    "ML = test_set['ML_target']\n",
    "ML.to_csv('ML.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create design matrix...\n",
      " complete 99%\n",
      "evaluating with W_MAP...\n",
      "evaluating with W_MAP...\n",
      "469.700476234 1545.15889382\n"
     ]
    }
   ],
   "source": [
    "# MAP\n",
    "v = 20\n",
    "t = train[:1000]\n",
    "val, tr = np.split(t, [len(t)//5])\n",
    "clf3 = bayesian_linear_regression()\n",
    "clf3.create_peak_gaussian_basis(tr, v, v, 70, 70, 25, 25)\n",
    "clf3.fit_with_W_MAP(tr[['X','Y']], tr['target'], reg=0.1)\n",
    "train_err = clf3.evaluate_W_MAP(tr[['X','Y']], tr['target'])\n",
    "val_err = clf3.evaluate_W_MAP(val[['X', 'Y']], val['target'])\n",
    "print(train_err, val_err)\n",
    "lst = np.array([clf3.predict_with_W_MAP(row['X'], row['Y']) for index, row in test_set.iterrows()])\n",
    "#test_set['MAP_target'] = lst\n",
    "#MAP = test_set['MAP_target']\n",
    "#MAP.to_csv('MAP1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create design matrix...\n",
      " complete 99%\n",
      "range(1000000, 20000001, 1000000)\n",
      "beta 1000000\n",
      "compute W_MAP 1/5 ...\n",
      "evaluating with W_MAP...\n",
      "train fold 0 21.4115121294\n",
      "evaluating with W_MAP...\n",
      "val fold 0 11458.3394641\n",
      "compute W_MAP 2/5 ...\n",
      "evaluating with W_MAP...\n",
      "train fold 1 33.1279911246\n",
      "evaluating with W_MAP...\n",
      "val fold 1 12165.0162185\n",
      "compute W_MAP 3/5 ...\n",
      "evaluating with W_MAP...\n",
      "train fold 2 45.0720503319\n",
      "evaluating with W_MAP...\n",
      "val fold 2 15096.5289616\n",
      "compute W_MAP 4/5 ...\n",
      "evaluating with W_MAP...\n",
      "train fold 3 26.3624129399\n",
      "evaluating with W_MAP...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1915226915aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesian_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_peak_gaussian_basis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_with_W_MAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_W_MAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mval_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_W_MAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mfit_with_W_MAP\u001b[0;34m(self, input_data, target, k_fold, show, s, beta, reg)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                     \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_W_MAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mval_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mevaluate_W_MAP\u001b[0;34m(self, test_data_input, target, W_MAP)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_with_W_MAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_MAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9b4843eb1703>\u001b[0m in \u001b[0;36mpredict_with_W_MAP\u001b[0;34m(self, x, y, W_MAP)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_basis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_MAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mpredict\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mW_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_basis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-640014073dc6>\u001b[0m in \u001b[0;36mprobability\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         self.prob = (np.exp(-((x-self.mean_x)**2)/(2*self.variance_x**2) - \n\u001b[1;32m     12\u001b[0m                              ((y-self.mean_y)**2)/(2*self.variance_y**2)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cross validation with W_MAP for BETA\n",
    "t = train[:500]\n",
    "val, tr = np.split(t, [len(t)//5])\n",
    "clf2 = bayesian_linear_regression()\n",
    "clf2.create_peak_gaussian_basis(tr, 20, 20, 70, 70, 25, 25)\n",
    "clf2.fit_with_W_MAP(tr[['X','Y']], tr['target'], 5)\n",
    "train_err = clf2.evaluate_W_MAP(tr[['X','Y']], tr['target'])\n",
    "val_err = clf2.evaluate_W_MAP(val[['X', 'Y']], val['target'])\n",
    "print(train_err, val_err)\n",
    "lst = np.array([clf2.predict_with_W_MAP(row['X'], row['Y']) for index, row in test_set.iterrows()])\n",
    "test_set['MAP_target'] = lst\n",
    "MAP = test_set['MAP_target']\n",
    "MAP.to_csv('MAP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create design matrix...\n",
      " complete 99%\n",
      "creating predictive distribution model\n",
      "compute S_N_inv\n",
      "compute m_N\n",
      "evaluating with predictive distribution function...\n",
      "evaluating with predictive distribution function...\n",
      "1371.64250714 1698.51654673\n"
     ]
    }
   ],
   "source": [
    "# predictive dist\n",
    "clf1 = bayesian_linear_regression()\n",
    "t = train[:500]\n",
    "val, tr = np.split(t, [len(t)//5])\n",
    "v = 20\n",
    "clf1.create_peak_gaussian_basis(tr, v, v, 70, 70, 25, 25)\n",
    "clf1.fit_with_predictive_distribution_function(tr[['X','Y']], tr['target'])\n",
    "train_err = clf1.evaluate_predictive_distribution_function(tr[['X','Y']], tr['target'])\n",
    "val_err = clf1.evaluate_predictive_distribution_function(val[['X', 'Y']], val['target'])\n",
    "print(train_err, val_err)\n",
    "lst = np.array([clf1.predict_with_predictive_distribution_function(row['X'], row['Y']) for index, row in test_set.iterrows()])\n",
    "test_set['bayesian_target'] = lst\n",
    "bayes = test_set['bayesian_target']\n",
    "bayes.to_csv('Bayesian.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
